{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dynamics:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw7dynamics=Dynamics()\n",
    "hw7dynamics.S0 = 1\n",
    "hw7dynamics.r = 0.03\n",
    "hw7dynamics.sigma = 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Contract:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw7contract=Contract() \n",
    "hw7contract.K = 1.1 \n",
    "hw7contract.T = 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MC:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw7MC=MC()\n",
    "hw7MC.M = 100000 # Number of paths  \n",
    "hw7MC.N = 4     # Number of time periods  \n",
    "hw7MC.seed = 0  # Seeding the random number generator with a specified number helps make the calculations reproducible\n",
    "\n",
    "hw7MC.algorithm = 'value'   \n",
    "#'value' for Value-based approach (Longstaff-Schwartz) -- problem 1\n",
    "#'policy' for Policy optimization -- problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Policy optimization approach, problem 2\n",
    "#\n",
    "# If b<<0 then this function essentially returns nearly 1 if X<a, or nearly 0 if X>a\n",
    "# but with some smoothing of the discontinuity, using a sigmoid function, to help the optimizer\n",
    "\n",
    "def softExercise(X,a,b):\n",
    "    return 1/(1+np.exp(-b*(X-a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Policy optimization approach, problem 2\n",
    "\n",
    "def negofMCaverageOfExpectedPayouts(coefficients, x, exercisePayoff, continuationPayoff):\n",
    "\n",
    "    p = softExercise(x,*coefficients)    \n",
    "\n",
    "    # p and exercisePayoff and continuationPayoff are all length-M arrays\n",
    "\n",
    "    return -(p*exercisePayoff + (1-p)*continuationPayoff).mean()\n",
    "\n",
    "## You fill in, what to return.  It should be the negative of the expression inside the max() on the homework sheet.\n",
    "## Need to take the negative because we are calling \"minimize\" but we want to do _maximization_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pricer_americanPut_GBM_LSM(contract,dynamics,MC):\n",
    "\n",
    "    np.random.seed(MC.seed)  #seed the random number generator\n",
    "    \n",
    "    r=dynamics.r\n",
    "    sigma=dynamics.sigma\n",
    "    S0=dynamics.S0\n",
    "\n",
    "    K=contract.K\n",
    "    T=contract.T\n",
    "\n",
    "    N=MC.N\n",
    "    M=MC.M\n",
    "    dt=T/N\n",
    "\n",
    "    Z = np.random.randn(M, N)\n",
    "    \n",
    "    paths = S0*np.exp((r-sigma**2/2)*dt*np.tile(np.arange(1,N+1),(M,1))+sigma*np.sqrt(dt)*np.cumsum(Z,axis=1))\n",
    "    \n",
    "    payoffDiscounted = np.maximum(0,K-paths[:,-1])\n",
    "    #This is the payoff (cashflow) along each path,\n",
    "    #discounted to time nn (for nn=N,N-1,...)\n",
    "    #It corresponds to the far right-hand column in each page of the\n",
    "    #Excel worksheet\n",
    "    #I'm initializing it for time nn=N.\n",
    "\n",
    "    #You could make payoffDiscounted\n",
    "    #to be a matrix because it depends on nn.\n",
    "    #But I will just reuse a 1-dimensional array,\n",
    "    #by overwriting the time nn+1 entries at time nn.        \n",
    "\n",
    "    for nn in np.arange(N-1,0,-1):\n",
    "        continuationPayoffDiscounted = np.exp(-r*dt)*payoffDiscounted\n",
    "        # This is the CONTINUATION payoff (cashflow) along each path,\n",
    "        # discounted to time nn (for nn=N-1,N-2,...)\n",
    "        # It corresponds to the blue column in each page of the Excel worksheet\n",
    "        # Note that payoffDiscounted comes from the previous iteration \n",
    "        # -- which was at time nn+1.  So now we discount back to time nn.\n",
    "\n",
    "        X=paths[:,nn-1]               \n",
    "        exerciseValue = K-X\n",
    "        \n",
    "        if MC.algorithm == 'value': \n",
    "            # This is the value function (Longstaff-Schwartz) approach.  For problem 1\n",
    "\n",
    "            basisfunctions = np.stack((np.ones(M), X, X**2),axis = -1)\n",
    "            # FILL THIS IN.  You may use np.stack\n",
    "                    # This will be an M-by-3 array containing the basis functions (Same ones as L7.8-7.9, and Excel)\n",
    "            reg = LinearRegression(fit_intercept = False).fit(basisfunctions, continuationPayoffDiscounted)\n",
    "            \n",
    "            coefficients = reg.coef_  \n",
    "                    # This will be an array of 3 estimated \"betas\".\n",
    "            \n",
    "            estimatedContinuationValue = reg.predict(basisfunctions)# FILL THIS IN with an array of length M. \n",
    "                    # This is similar to the Red column in Excel\n",
    "            \n",
    "            whichPathsToExercise = (exerciseValue >= np.maximum(estimatedContinuationValue,0))\n",
    "                    #This is a length-M array of Booleans\n",
    "        \n",
    "        elif MC.algorithm == 'policy':\n",
    "            # This is the policy optimization approach to reinforcement learning.  For problem 2\n",
    "            \n",
    "            (a_opt,b_opt) = scipy.optimize.minimize(\n",
    "                negofMCaverageOfExpectedPayouts,(0,0),args=(X,exerciseValue,continuationPayoffDiscounted),method='Nelder-Mead').x\n",
    "                #Chose Nelder-Mead optimizer because it is generating reasonable results with minimal coding effort\n",
    "                #But gradient methods, done properly, usually run faster\n",
    "    \n",
    "            whichPathsToExercise = np.where(softExercise(X,a_opt,b_opt)>=0.5,1,0) * np.where(exerciseValue>0,1,0)\n",
    "                #FILL THIS IN, using the right-hand side of the last equation on the homework sheet \n",
    "                #This obtains the hard exercise decision from the optimized soft exercise function\n",
    "                #It should be a length-M array of Booleans (as it was in the \"value\" approach.  \n",
    "                #But here it comes from the softExercise function)\n",
    "\n",
    "        else:\n",
    "            raise ValueError('Unknown algorithm type')\n",
    "        \n",
    "        \n",
    "        payoffDiscounted[whichPathsToExercise] = exerciseValue[whichPathsToExercise] # FILL THIS IN -- see the \"discounted cashflow along path\" column in Excel \n",
    "        payoffDiscounted[np.logical_not(whichPathsToExercise)] = continuationPayoffDiscounted[np.logical_not(whichPathsToExercise)]# FILL THIS IN -- see the \"discounted cashflow along path\" column in Excel\n",
    "\n",
    "    # The time-0 calculation needs no regression\n",
    "    continuationPayoffDiscounted = np.exp(-r*dt)*payoffDiscounted;\n",
    "    estimatedContinuationValue = np.mean(continuationPayoffDiscounted);\n",
    "    putprice = max(K-S0,estimatedContinuationValue);\n",
    "        \n",
    "    return(putprice)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16223563140067124"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pricer_americanPut_GBM_LSM(hw7contract,hw7dynamics,hw7MC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-4b7a501e3e82>:7: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-b*(X-a)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.15303872363875284"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hw7MC.algorithm = 'policy'\n",
    "pricer_americanPut_GBM_LSM(hw7contract,hw7dynamics,hw7MC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07778384164703311\n",
      "6.200000000009381\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm \n",
    "import numpy as np \n",
    "\n",
    "def call_price(d):\n",
    "    return 100*(norm.cdf(d)-norm.cdf(-d))\n",
    "\n",
    "target = 6.20\n",
    "\n",
    "low = 0\n",
    "high = 0.5\n",
    "mid = (low+high)/2\n",
    "\n",
    "while abs(call_price(mid)-target) > 1e-10:\n",
    "    \n",
    "    if call_price(mid) > target:\n",
    "        high = mid\n",
    "        mid = (low + high)/2 \n",
    "        \n",
    "    else:\n",
    "        low = mid\n",
    "        mid = (low + high)/2\n",
    "        \n",
    "print(mid)\n",
    "print(call_price(mid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2200059275814308"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = (mid*2)/np.sqrt(0.5)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0025913040854828855"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = (s**2)/2-0.1*0.25**2-0.15*0.32**2\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10180970652119346"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(4*r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22000368178737373"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(2*(0.1*0.25**2+0.15*0.32**2+0.25*0.1018**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d(s,t):\n",
    "    return 0.5*s*np.sqrt(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1530945127879573"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_price(d(0.25,0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.859175592360261"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_price(d(0.294,0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05855"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=0.36\n",
    "r=(s**2)/2-0.1*0.25**2\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6247666230948428"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.sqrt(r/0.15)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 0.25\n",
    "np.sqrt(2*(0.1*a**2+0.15*b**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5091168824543142"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(4*(0.1*a**2+0.15*b**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
